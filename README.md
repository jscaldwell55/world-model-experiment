# World Model Experiments: Persistent Learning with ACE Memory

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Current Focus:** Preventing belief traps in persistent world model learning through methodology-aware memory systems.

This project explores how LLM-based agents can learn persistent world models across episodes without falling into "belief traps"â€”situations where early incorrect beliefs prevent learning correct knowledge later.

**Status:** âœ… ACE Memory System Implemented & Validated (2025-11-17)

---

## Quick Links

- **[ACE Implementation Summary](ACE_IMPLEMENTATION_UPGRADE.md)** - New memory system architecture
- **[Controlled Belief Trap Test](test_belief_trap_controlled.py)** - Validation of core functionality
- **[Original Study Results](RESULTS_SUMMARY.md)** - Completed ACE vs Interactive Learning study
- **[Preregistration](preregistration.md)** - Original study hypotheses (commit `cd41f0c`)

---

## Current System: SimpleWorldModel + ACE Memory

### The Problem: Belief Traps in Persistent Learning

**Original System (Consolidation-based):**
```
Episode 1-2: Mixed power settings â†’ Learn heating_rate = 1.0Â°C/s (wrong!)
            Score â‰¥75% â†’ Gets consolidated âœ…
            High confidence because scores are good

Episode 3:   Consistent HIGH power â†’ Learn heating_rate = 2.5Â°C/s (correct!)
            âŒ REJECTED as outlier (z-score > 2.5)

Result: System stuck with wrong belief forever
```

**Why it happens:**
- Episode score (answer quality) â‰  methodology quality
- High-scoring episodes can have flawed data collection
- Outlier detection rejects correct observations that differ from consolidated beliefs

### The Solution: ACE Memory System

**ACE (Agentic Context Engineering) Playbook:**
```
Episode 1-2: Store with LOW reliability tag
            "Power toggle detected - mixed contexts (averaged data)"

Episode 3:   Store with HIGH reliability tag
            "Consistent power setting - reliable measurement"
            âœ… NOT rejected despite 2x difference!

Result: Agent sees both observations with methodology warnings
```

**Key Innovation:** Separate **score** (answer quality) from **reliability** (methodology quality)

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EPISODE RUNTIME                 â”‚
â”‚ 1. ACE Playbook provides context        â”‚
â”‚ 2. SimpleWorldModel initializes         â”‚
â”‚    (prior_strength=0.1 - weak priors!)  â”‚
â”‚ 3. Real-time Bayesian updates           â”‚
â”‚ 4. Episode completes                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AFTER EPISODE: ACE LEARNS          â”‚
â”‚ 1. Reflector analyzes trajectory        â”‚
â”‚    - Detects methodology issues          â”‚
â”‚    - Tags reliability (HIGH/MEDIUM/LOW)  â”‚
â”‚ 2. Curator generates delta updates      â”‚
â”‚ 3. Playbook updated (NOT consolidated!) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NEXT EPISODE: CONTEXT PROVIDED        â”‚
â”‚ Agent sees:                              â”‚
â”‚ âœ“ HIGH reliability observations          â”‚
â”‚ âš ï¸ LOW reliability observations          â”‚
â”‚ ğŸ’¡ Methodology warnings                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

**1. SimpleWorldModel Agent** (`agents/simple_world_model.py`)
- Evolution of ACTOR with persistent memory
- Real-time Bayesian belief updates (prior_strength=0.1)
- Statistical tracking for noise filtering
- Causal relationship learning
- **Unchanged from ACTOR:** Core Bayesian inference

**2. ACE Playbook** (`memory/ace_playbook.py`)
- Stores observations with context and methodology tags
- Reflects on trajectories to assess reliability
- Curates delta updates (no consolidation!)
- Generates natural language context with warnings
- **Key:** Never rejects observations as outliers

**3. Methodology Detection**
- Detects power toggles (HotPot) â†’ LOW reliability
- Detects limited exploration (ChemTile) â†’ LOW reliability
- Detects systematic exploration (SwitchLight) â†’ HIGH reliability
- Tags reliability independently from episode score

---

## Validation Results

### âœ… Controlled Belief Trap Test (Priority 1)

**Test Scenario:**
```bash
python test_belief_trap_controlled.py
```

**Results:**
```
Phase 1: Episodes 1-2 (MIXED power)
  â†’ 1.2-1.4Â°C/s learned, tagged LOW reliability âœ…

Phase 2: Episode 3 (HIGH power) - CRITICAL TEST
  â†’ 2.5Â°C/s learned, tagged HIGH reliability âœ…
  â†’ NOT rejected as outlier âœ…

Phase 3: Episode 4 (HIGH power)
  â†’ 2.6Â°C/s learned, HIGH reliability âœ…

Phase 4: Episode 5 (LOW power)
  â†’ 0.5Â°C/s learned, HIGH reliability âœ…

âœ… All 5 observations stored (no rejection)
âœ… Reliability correctly tagged in 100% of cases
âœ… Core value proposition VALIDATED
```

**What this proves:**
- ACE prevents belief traps by storing all observations
- Methodology quality tagged separately from score
- Correct observations not rejected even when very different from prior beliefs

### âœ… 9-Episode Validation Test

**Configuration:** 3 episodes per domain (HotPot, ChemTile, SwitchLight)

**Results:**
```
Overall accuracy: 84.6%
  - ChemTile:    95.0% (excellent!)
  - HotPot:      79.7% (all episodes had power toggles)
  - SwitchLight: 79.2% (improved from 69% â†’ 84% across episodes)

Methodology Detection:
  - HotPot:      3/3 correctly tagged LOW (power toggles)
  - ChemTile:    3/3 tagged LOW (limited exploration)
  - SwitchLight: 3/3 correctly tagged HIGH (systematic exploration)

Accuracy: 100% in methodology classification
```

**Key findings:**
1. ACE correctly detects methodology issues in real episodes
2. Performance competitive with baselines (84.6% overall)
3. Learning progression visible (SwitchLight: 69% â†’ 84%)
4. No observations rejected despite methodology diversity

---

## Quick Start

### Prerequisites

```bash
# Install dependencies
pip install -r requirements.txt

# Set API key
export ANTHROPIC_API_KEY="sk-ant-api03-..."
```

### Run Validation Test

```bash
# Controlled belief trap test (free, local simulation)
python test_belief_trap_controlled.py

# 9-episode validation (~$1.50, 16 minutes)
python scripts/run_experiment_parallel.py \
  --config config_ace_validation_9ep.yaml \
  --output-dir results/ace_validation_9ep \
  --workers 1

# 30-episode comprehensive validation (~$5, 2 hours)
python scripts/run_experiment_parallel.py \
  --config config_ace_validation_30ep.yaml \
  --output-dir results/ace_validation_30ep \
  --workers 1
```

### Analyze Results

```bash
# Analyze learning progression
python analyze_ace_learning.py --results-dir results/ace_validation_9ep

# View ACE playbooks
cat memory/domains/hot_pot/playbook.json | jq '.observations[] | {episode_id, reliability, reason}'
cat memory/domains/chem_tile/playbook.json | jq '.observations'
cat memory/domains/switch_light/playbook.json | jq '.observations'
```

---

## Project Structure

```
world-model-experiment/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ ACE_IMPLEMENTATION_UPGRADE.md       # ACE memory architecture
â”œâ”€â”€ test_belief_trap_controlled.py      # Validation test
â”œâ”€â”€ analyze_ace_learning.py             # Results analysis
â”‚
â”œâ”€â”€ config_ace_validation_9ep.yaml      # 9-episode test config
â”œâ”€â”€ config_ace_validation_30ep.yaml     # 30-episode test config
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ simple_world_model.py           # World model agent with ACE
â”‚   â”œâ”€â”€ actor.py                        # Original ACTOR (Bayesian)
â”‚   â”œâ”€â”€ observer.py                     # Baseline (no learning)
â”‚   â””â”€â”€ ace.py                          # Original ACE agent
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ ace_playbook.py                 # NEW: ACE memory system
â”‚   â””â”€â”€ domain_memory.py                # OLD: Consolidation-based (deprecated)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ belief_state.py                 # Belief representations
â”‚
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ hot_pot.py                      # Temperature dynamics
â”‚   â”œâ”€â”€ switch_light.py                 # Wiring inference
â”‚   â””â”€â”€ chem_tile.py                    # Chemical reactions
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ runner.py                       # Episode orchestration
â”‚   â”œâ”€â”€ prompts.py                      # LLM prompts
â”‚   â””â”€â”€ provenance.py                   # Version tracking
â”‚
â””â”€â”€ memory/domains/                     # ACE playbooks (gitignored)
    â”œâ”€â”€ hot_pot/
    â”‚   â”œâ”€â”€ playbook.json               # Observations + methodology tags
    â”‚   â”œâ”€â”€ episodes/*.json             # Raw episode data
    â”‚   â””â”€â”€ metadata/stats.json
    â”œâ”€â”€ chem_tile/
    â””â”€â”€ switch_light/
```

---

## Key Metrics

### Belief Trap Prevention
- **Observation retention:** 100% (no rejections)
- **Methodology detection accuracy:** 100% in validation tests
- **Reliability tagging:** HIGH/MEDIUM/LOW based on data collection quality

### Performance
- **Overall accuracy:** 84.6% (9-episode test)
- **ChemTile:** 95.0% (range: 92-100%)
- **HotPot:** 79.7% (range: 73-83%)
- **SwitchLight:** 79.2% (range: 69-84%)

### Efficiency
- **Tokens per episode:** ~23k (input + output)
- **Cost per episode:** ~$0.17 (Claude Sonnet 4.5)
- **Time per episode:** ~2 minutes

---

## Comparison to Consolidation-Based Memory

| Aspect | Consolidation (Old) | ACE Memory (New) |
|--------|-------------------|------------------|
| **Storage** | Averaged beliefs | Individual observations |
| **Quality Control** | Outlier rejection | Methodology tagging |
| **Score vs Reliability** | Conflated | Separated |
| **Belief Traps** | âŒ Vulnerable | âœ… Prevented |
| **Data Loss** | âŒ Yes (outliers rejected) | âœ… No (all stored) |
| **Context Type** | Consolidated values | Natural language warnings |
| **Prior Strength** | Adaptive (0.1-0.3) | Fixed (0.1) |

**Critical Difference:** ACE stores observations with context instead of consolidating to single values. This prevents rejection of correct but different observations.

---

## Research Context

### Original Study (Completed 2025-10-31)

This project originated from a preregistered study comparing ACE vs Interactive Learning:

**Key Findings:**
- **ACTOR (Bayesian):** 81.2% accuracy
- **ACE (Playbook):** 70.3% accuracy
- **Critical insight:** Qualitative playbooks struggle with quantitative probability questions

**Full results:** [RESULTS_SUMMARY.md](RESULTS_SUMMARY.md)

### Current Development (2025-11-17)

Focus shifted to **persistent learning** and **belief trap prevention**:

**Problem identified:** Consolidation-based memory creates belief traps when:
1. Early episodes have good scores but flawed methodology
2. Later episodes have better methodology but different observations
3. Outlier detection rejects the correct observations

**Solution implemented:** ACE memory system with methodology tracking

---

## Technical Details

### Methodology Detection (HotPot Example)

```python
# LOW Reliability (power toggles)
Actions: ['measure_temp', 'toggle_power', 'measure_temp', 'toggle_power']
Context: {'power_setting': 'MIXED'}
Reliability: LOW
Reason: "Multiple power toggles (2) - averaged across contexts"

# HIGH Reliability (consistent power)
Actions: ['measure_temp', 'wait', 'measure_temp', 'wait']
Context: {'power_setting': 'HIGH'}
Reliability: HIGH
Reason: "Consistent power setting - reliable measurement"
```

### Context Generation

```
=== HotPotLab KNOWLEDGE BASE ===

âœ“ HIGH-RELIABILITY OBSERVATIONS:
  â€¢ Episode ep003 (score: 88%): heating_rate ~2.50Â°C/s [power: HIGH]
    â†’ Consistent power setting - reliable measurement

âš ï¸ LOW-RELIABILITY OBSERVATIONS (USE WITH CAUTION):
  â€¢ Episode ep001 (score: 85%): heating_rate ~1.20Â°C/s [power: MIXED]
    â†’ Power toggle detected - mixed contexts (averaged data)

ğŸ’¡ RECOMMENDATION:
  Initialize with WEAK priors (prior_strength=0.1)
  Trust current observations over past averages
  Pay attention to context (settings, actions taken)
```

### Prior Strength

**Critical parameter:** `prior_strength = 0.1` (fixed)

- Weak priors ensure agent adapts quickly to current observations
- ACE context provides guidance without strong constraints
- Prevents over-reliance on potentially unreliable historical data

---

## Future Work

### Immediate Next Steps
1. âœ… **Controlled belief trap test** - COMPLETE
2. ğŸ”„ **30-episode validation** - IN PROGRESS
3. â¸ï¸ **Compare to consolidation baseline** - Planned
4. â¸ï¸ **Long-term learning (100+ episodes)** - Planned

### Research Directions
1. **Continuous reliability scores** (vs. HIGH/MEDIUM/LOW)
2. **Cross-domain transfer learning**
3. **Offline consolidation** (Dream â†’ NeSy â†’ Fine-tuning)
4. **Exploration strategy optimization**

### Open Questions
- How many episodes before HIGH reliability data emerges naturally?
- Can ACE be extended to other learning domains?
- What is optimal playbook size (currently capped at 10 observations)?
- How to balance context length vs. information density?

---

## Citation

If you use this work in your research, please cite:

```bibtex
@misc{caldwell2025worldmodel,
  title={Preventing Belief Traps in Persistent World Model Learning},
  author={Caldwell, Jay},
  year={2025},
  howpublished={\url{https://github.com/jaycald/world-model-experiment}},
  note={ACE-based memory system for methodology-aware learning}
}
```

For the original ACE vs Interactive Learning study:

```bibtex
@misc{caldwell2025ace,
  title={World Model Experiments: ACE vs Interactive Learning},
  author={Caldwell, Jay},
  year={2025},
  howpublished={\url{https://github.com/jaycald/world-model-experiment}},
  note={Preregistered study comparing context engineering vs. Bayesian learning}
}
```

---

## References

### ACE Framework
- **ACE Paper:** ["Agentic Context Engineering"](https://arxiv.org/abs/2510.04618) (2024)
- **Implementation:** Original ACE agent vs. new ACE memory system

### Theoretical Background
- **Belief trap problem:** High-scoring but flawed methodology prevents learning
- **Methodology tracking:** Separate data quality from task performance
- **Context vs. consolidation:** Natural language warnings vs. averaged values

---

## Contact

**Jay Caldwell**
Independent Researcher
jay.s.caldwell@gmail.com

For questions:
- **ACE Memory Implementation:** `memory/ace_playbook.py`
- **Validation Tests:** `test_belief_trap_controlled.py`
- **Original Study:** [RESULTS_SUMMARY.md](RESULTS_SUMMARY.md)

---

## License

MIT License - See [LICENSE](LICENSE) file

Copyright (c) 2025 Jay Caldwell

---

**Last updated:** 2025-11-17 | ACE Memory System validated | Belief trap prevention confirmed
