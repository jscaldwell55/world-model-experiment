#!/usr/bin/env python3
"""
Debug FTB Filtering Issue

Investigates why FTB filtered all 6 synthetics in hot_pot domain.

Hypotheses:
1. Too strict fidelity threshold (min_fidelity=0.7)
2. Aggressive deduplication (max_similarity=0.9)
3. Bug in FTB implementation
"""

import sys
import json
import numpy as np
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from memory.ace_playbook import ACEPlaybook
from utils.offline_consolidation import OfflineConsolidation
from utils.context_spec import get_context_spec
from utils.fine_tuning_bridge import fine_tuning_bridge_v1, episode_similarity


def jaccard_similarity(ep1, ep2):
    """Compute Jaccard similarity between episodes based on state-action sequences"""
    try:
        # Get observations from episodes
        obs1 = ep1.get('observations', [])
        obs2 = ep2.get('observations', [])

        if not obs1 or not obs2:
            # If no observations, compare contexts
            ctx1 = str(sorted(ep1.get('context', {}).items())) if isinstance(ep1.get('context'), dict) else str(ep1.get('context'))
            ctx2 = str(sorted(ep2.get('context', {}).items())) if isinstance(ep2.get('context'), dict) else str(ep2.get('context'))
            return 1.0 if ctx1 == ctx2 else 0.0

        # Extract state tuples (temp, power) from observations
        def extract_states(observations):
            states = []
            for obs in observations:
                temp = obs.get('measured_temp', obs.get('temp', 0))
                power = obs.get('context', {}).get('power_setting', 'UNKNOWN')
                states.append((round(temp, 1), power))
            return set(states)

        set1 = extract_states(obs1)
        set2 = extract_states(obs2)

        if not set1 and not set2:
            return 1.0
        if not set1 or not set2:
            return 0.0

        intersection = len(set1 & set2)
        union = len(set1 | set2)

        return intersection / union if union > 0 else 0.0

    except Exception as e:
        print(f"Warning: Jaccard similarity calculation failed: {e}")
        return 0.0


def debug_ftb_filtering():
    """Investigate why FTB filtered all 6 synthetics"""

    print("=" * 80)
    print("FTB FILTERING DEBUG")
    print("=" * 80)

    domain = "hot_pot"
    context_spec = get_context_spec(domain)

    # Step 1: Load playbook and run OC to generate synthetics
    print(f"\n[1] Loading playbook for {domain}...")
    playbook = ACEPlaybook(domain)

    observations = playbook.playbook.get('observations', [])
    print(f"  Total observations: {len(observations)}")

    high_reliability_obs = [obs for obs in observations if obs.get('reliability') == 'HIGH']
    print(f"  HIGH reliability: {len(high_reliability_obs)}")

    # Step 2: Run OC to generate synthetics
    print(f"\n[2] Running Offline Consolidation...")
    oc = OfflineConsolidation()
    consolidated = oc.consolidate(domain, context_spec)

    print(f"\n  Synthetics generated: {len(consolidated.synthetic_episodes)}")
    print(f"  Gate status: {consolidated.gate_status}")
    print(f"  CV error: {consolidated.cv_error:.1%}")

    if len(consolidated.synthetic_episodes) == 0:
        print("\n‚ùå NO SYNTHETICS GENERATED BY OC")
        print("   This is the root cause - OC didn't generate any synthetics!")
        return

    # Step 3: Analyze each synthetic before FTB filtering
    print(f"\n[3] Analyzing synthetics BEFORE FTB filtering...")
    print("-" * 80)

    for i, synthetic in enumerate(consolidated.synthetic_episodes):
        print(f"\nSynthetic {i + 1}/{len(consolidated.synthetic_episodes)}:")
        print(f"  Episode ID: {synthetic.get('episode_id', 'N/A')}")

        fidelity = synthetic.get('fidelity_score', 0.0)
        print(f"  Fidelity: {fidelity:.3f}")

        context = synthetic.get('context', 'N/A')
        print(f"  Context: {context}")

        source_context = synthetic.get('source_context', 'N/A')
        print(f"  Source context: {source_context}")

        # Check fidelity threshold
        if fidelity < 0.7:
            print(f"  ‚ö†Ô∏è  BELOW THRESHOLD: Fidelity {fidelity:.3f} < 0.7")
        else:
            print(f"  ‚úÖ ABOVE THRESHOLD: Fidelity {fidelity:.3f} >= 0.7")

        # Check deduplication using episode_similarity (same as FTB)
        print(f"\n  Checking similarity to existing episodes...")
        max_similarity = 0.0
        most_similar_idx = -1

        for j, existing in enumerate(observations):
            sim = episode_similarity(synthetic, existing)
            if sim > max_similarity:
                max_similarity = sim
                most_similar_idx = j

        print(f"  Max similarity: {max_similarity:.3f} (vs existing episode {most_similar_idx})")

        if max_similarity > 0.9:
            print(f"  ‚ö†Ô∏è  TOO SIMILAR: {max_similarity:.3f} > 0.9 threshold")
        else:
            print(f"  ‚úÖ UNIQUE ENOUGH: {max_similarity:.3f} <= 0.9")

        # Overall verdict
        should_pass = fidelity >= 0.7 and max_similarity <= 0.9
        print(f"\n  VERDICT: {'‚úÖ SHOULD BE ACCEPTED' if should_pass else '‚ùå SHOULD BE REJECTED'}")

    # Step 4: Run actual FTB and see what it does
    print(f"\n[4] Running FTB v1 with default thresholds...")
    print("-" * 80)

    result = fine_tuning_bridge_v1(
        consolidated,
        domain,
        min_fidelity=0.7,
        max_similarity=0.9
    )

    if result is None:
        print("‚ùå FTB returned None (gate failed)")
        print(f"   Gate status: {consolidated.gate_status}")
        print(f"   Reason: {consolidated.reason}")
    else:
        # Count synthetics in result
        all_obs = result.playbook.get('observations', [])
        saved_synthetics = [obs for obs in all_obs if obs.get('is_synthetic', False)]

        print(f"‚úÖ FTB completed successfully")
        print(f"  Synthetics saved: {len(saved_synthetics)}")
        print(f"  Total observations: {len(all_obs)}")

    # Step 5: Statistical analysis
    print(f"\n[5] Statistical Analysis")
    print("-" * 80)

    # Hypothesis 1: Too strict fidelity threshold
    fidelities = [s.get('fidelity_score', 0.0) for s in consolidated.synthetic_episodes]

    print(f"\nFidelity distribution:")
    print(f"  Mean:   {np.mean(fidelities):.3f}")
    print(f"  Median: {np.median(fidelities):.3f}")
    print(f"  Min:    {np.min(fidelities):.3f}")
    print(f"  Max:    {np.max(fidelities):.3f}")
    print(f"  Std:    {np.std(fidelities):.3f}")

    below_threshold = sum(1 for f in fidelities if f < 0.7)
    print(f"\n  Below threshold (0.7): {below_threshold}/{len(fidelities)}")

    if np.max(fidelities) < 0.7:
        print(f"\n  üîç HYPOTHESIS 1: CONFIRMED")
        print(f"     ALL synthetics have fidelity < 0.7")
        print(f"     Recommendation: Lower threshold to 0.5 or 0.6")
    elif below_threshold > 0:
        print(f"\n  üîç HYPOTHESIS 1: PARTIAL")
        print(f"     {below_threshold} synthetics below threshold")
        print(f"     Recommendation: Consider lowering threshold to {np.median(fidelities):.2f}")
    else:
        print(f"\n  ‚úÖ HYPOTHESIS 1: REJECTED")
        print(f"     All synthetics pass fidelity threshold")

    # Hypothesis 2: Aggressive deduplication
    print(f"\n\nSimilarity analysis:")

    for i, synthetic in enumerate(consolidated.synthetic_episodes):
        similarities = [
            episode_similarity(synthetic, existing)
            for existing in observations
        ]
        max_sim = max(similarities) if similarities else 0.0
        avg_sim = np.mean(similarities) if similarities else 0.0

        print(f"  Synthetic {i + 1}:")
        print(f"    Max similarity: {max_sim:.3f}")
        print(f"    Avg similarity: {avg_sim:.3f}")

        if max_sim > 0.9:
            print(f"    ‚ö†Ô∏è  Too similar to existing data (> 0.9)")

    too_similar_count = sum(
        1 for s in consolidated.synthetic_episodes
        if max(episode_similarity(s, e) for e in observations) > 0.9
    )

    if too_similar_count == len(consolidated.synthetic_episodes):
        print(f"\n  üîç HYPOTHESIS 2: CONFIRMED")
        print(f"     ALL synthetics too similar to existing (> 0.9)")
        print(f"     Recommendation: Relax threshold to 0.95")
    elif too_similar_count > 0:
        print(f"\n  üîç HYPOTHESIS 2: PARTIAL")
        print(f"     {too_similar_count} synthetics too similar")
        print(f"     Recommendation: Consider relaxing threshold")
    else:
        print(f"\n  ‚úÖ HYPOTHESIS 2: REJECTED")
        print(f"     All synthetics sufficiently unique")

    # Step 6: Recommendations
    print(f"\n[6] RECOMMENDATIONS")
    print("=" * 80)

    # Count how many would pass with relaxed thresholds
    relaxed_fidelity = 0.5
    relaxed_similarity = 0.95

    would_pass_relaxed = 0
    for synthetic in consolidated.synthetic_episodes:
        fidelity = synthetic.get('fidelity_score', 0.0)
        max_sim = max(episode_similarity(synthetic, e) for e in observations) if observations else 0.0

        if fidelity >= relaxed_fidelity and max_sim <= relaxed_similarity:
            would_pass_relaxed += 1

    # Count how many pass current thresholds
    current_pass_count = 0
    for s in consolidated.synthetic_episodes:
        fidelity = s.get('fidelity_score', 0.0)
        if observations:
            max_sim = max(episode_similarity(s, e) for e in observations)
            if fidelity >= 0.7 and max_sim <= 0.9:
                current_pass_count += 1
        elif fidelity >= 0.7:
            current_pass_count += 1

    print(f"\nWith current thresholds (fidelity‚â•0.7, similarity‚â§0.9):")
    print(f"  Expected to pass: {current_pass_count}")

    print(f"\nWith relaxed thresholds (fidelity‚â•{relaxed_fidelity}, similarity‚â§{relaxed_similarity}):")
    print(f"  Would pass: {would_pass_relaxed}")

    if would_pass_relaxed > 0:
        print(f"\n‚úÖ ACTION: Update FTB thresholds to:")
        print(f"   min_fidelity = {relaxed_fidelity}")
        print(f"   max_similarity = {relaxed_similarity}")
    else:
        print(f"\n‚ö†Ô∏è  WARNING: Even with relaxed thresholds, no synthetics would pass")
        print(f"   This suggests a deeper issue with synthetic generation")

    print("\n" + "=" * 80)


if __name__ == '__main__':
    debug_ftb_filtering()
